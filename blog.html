<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="images/website_logo.png">

    <title>HappenVR</title>

    <!-- CSS -->
    <link href="css/blog.css" rel="stylesheet">

  </head>

  <body>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.0/js/bootstrap.min.js"></script>
    <script src="js/main.js"></script>

    <div class="navbar-wrapper">
      <div class="container">
        <nav class="navbar navbar-inverse navbar-fixed-top">
          <div class="container">
            <div class="navbar-header page-scroll">
              <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              <a class="navbar-brand" href="index.html">
                <img id="nav_logo" alt="Brand" src="images/website_logo.png"/>
                <span>HappenVR</span>
              </a>
            </div>
            <div id="navbar" class="collapse navbar-collapse">
              <ul class="nav navbar-nav pull-right">
                <li><a href="blog.html" class="page-scroll">Blog</a></li>
                <li><a href="index.html#contact" class="page-scroll">Contact</a></li>
              </ul>
            </div>
          </div>
        </nav>
      </div>
    </div>

    <!-- BLOG ENTRY SECTION -->
    <div id="blog-section" class="container col-md-8 col-md-offset-2">

      <div class="row blog-entry">
        <div class="col-md-10 col-md-offset-1 section-title">
          <h1>HappenVR TENS Mesh Design and Fabrication</h1>
          <p class="subtitle">February 7, 2017 | by: Si Te Feng</p>
          <hr/>
        </div>

        <div class="col-md-10 col-md-offset-1">
          <p class="blog-body">
            At the center of our enhanced virtual reality experience is the custom designed glove with tactile feedback system. Tactile feedback is the simulation of touch, so that patients can not only see and listen to 3D objects in the virtual environment, but also touch and feel the objects too. To achieve this, team Happen has been working dilligently to design a TENS (Transcutaneous Electrical Neural Stimulation) mesh that touches the inner sides of the fingers. The TENS mesh is envisioned to be a flexible and thin piece of PCB (printed circuit board) with circular gold plated electrodes that are around 1mm in diameter and 2mm apart. The TENS mesh simulates the touch sensation by delivering a tiny varying current (around 1-3 mA) with various frequency, phase, and current travel patterns. 

            <br/><br/>Yesterday, the electrical team has successfully produced both anodic and cathodic electrical stimulation from a 4 by 4 electrode grid to the finger for the first time. The words anodic and cathodic refer to the current travel direction. For Anodic stimulation, positive current travels from the inner electrode to the outer electrodes concentrically, whereas cathodic stimulation does the opposite. The production of the sensation is a huge milestone for the team as it validates almost all of the previous engineering work that went into the design of the TENS circuit. The reliable sensation was made possible by the steady current provided by the current regulation circuit that the team has been working on for the last 3 months. The resulting stimulation feels as though the electrodes are pushing up against the finger, when in fact, there are no physical movements. When the input signal is set to be a 100 Î¼s period square wave, the resulting sensation is an occilating vertical force of around 12 Hz. The current understanding is that both increase in phase of the signal and output current would increase the force sensation. The photo below shows the testing setup from yesterday.

            </p>

            <img class="col-xs-8 col-xs-offset-2" src="images/church1.jpg"/>

            <p class="blog-body">
             Now that the prototype circuit has been validated, the electrical team has decided that the next step is to start on the PCB manufacturing process and reselect the electrical components from breadboard DIP components to PCB SMT components. This is to drastically reduce the size of the electrical circuit in preparation of the Mechatronics Symposium demonstration. In addition, the team will also use EAGLE to design PCB for both the current regulation circuit and TENS mesh. The TENS mesh will be printed on a ridgid PCB as usual during prototyping stages, but will be eventually converted to a flexible design. In order to try out different configurations, 2 TENS PCB will be designed: a 3 by 3 electrode grid and a 4 by 4 electrode grid. Each TENS PCB will be placed under one segment of the finger with a total of 14 pieces. Additional pieces might be placed in the palm area as well. 

            </p>

            <br/>
            <div class="row">
              <div class="col-xs-5 col-xs-offset-1">
                <img class="img-fit" src="images/pcb1.png"/>
                <p class="img-caption">TENS Mesh Driver PCB Design</p>
              </div>
              <div class="col-xs-4 col-xs-offset-1">
                <img class="img-fit" src="images/pcb2.png"/>
                <p class="img-caption">4x4 TENS Pad PCB Design</p>
              </div>
            </div>

            <br/>

            <p class="blog-body">The team plans on consolidating the design by the end of the week and send out the first patch of orders by next week. The PCBs will be ordered from PCBWay, which is a company that provides quality PCB printing services and fast shipping. We hope by quickly iterate though designs and trying many input signals with our virtual reality game, we can make a seemless tactile experience that will engage the patient at a level that has never been possible.
            </p>

            <div class="col-xs-12">
              <img class="col-xs-2 col-xs-offset-5" src="images/feather2.png"/>
            </div>
        </div>
      </div>

      <hr/>
      <!-- ************ -->

      <div class="row blog-entry">
        <div class="col-md-10 col-md-offset-1 section-title">
          <h1>New Virtual Environment Prototype with Unity 3D</h1>
          <p class="subtitle">January 28, 2017 | by: Si Te Feng</p>
          <hr/>
        </div>

        <div class="col-md-10 col-md-offset-1">
          <p class="blog-body">
            Today marks an exciting new milestone as the team completed the initial validation of using Unity 3D game engine as the main platform for the Happen virtual reality user interface. During the last few weeks, the team has been working on designing the game mechanics, modeling animated characters using Blender, and scripting interactions between game objects. The most significant progress, however, is getting Leap Motion sensor to be fully integrated with the virtual environment game prototype that we have created. Part of interaction was made possible thanks to the Leap Motion Orion SDK which includes a "User Interaction" module that allows the detected hands to hold onto a virtual object without letting the built in Unity physics engine to push the object away due to boundary interference. Although the SDK does not provide the full accurate touch callback that our virtual reality glove need, we have written a custom collision detector with spheres which tells the program exactly how deep did the user's fingers sink into the object and many other detailed parameters. With this level of information, we can then accurately control the glove stepper motor movement for force feedback, and accurately adjust the sensation intensity deliver by our TENS pads to the fingers. 

            <br/><br/>The game is called Rockaway, synonymous to the beach in New York, but is actually a first person rock defense game against slow moving polygon humanoids on a futuristic spaceship. The idea is to allow the users to exercise their upper limb and hand movements by repeatedly grabbing various shaped rocks from an altar and throwing them at the humanoids to gain points. If the humanoid reaches the person, the team is planning on reducing the health of the player, although that interaction has not yet been implemented. When the rock hits the humanoid, it plays the dying animation and is removed form the scene after a few seconds. We have custom made the polygon humanoid in Blender with a slew of animations, which includes crawling up from the ground, walking, crawling forward, dying while walking, dying while crawling, and jump attack. All of which will be eventually integrated into the final prototype for the 2017 Mechatronics Symposium demonstration.

          </p>

          <img class="col-xs-8 col-xs-offset-2" src="images/blender1.png"/>

          <p class="blog-body">
            The other game objects seen around the spaceship has been sourced from BlendSwap, a website where designers freely share their Blender creations. The team was fortunate enough to find detailed robot and turrent 3D models to use in our Rockaway game. This includes the nicely designed colored stripe spherical rocks that the player uses to throw at the humanoids.

            <br/><br/>The team is already in the process of the next step in the software development, which is writing serial communication scripts in C# and C to allow the Unity game running on Windows 10 desktop to freely communicate with the Arduino microcontroller. This is essential in bridging the gap between our custom glove hardware and the Unity + Oculus + Leap Motion package. 

            <br/><br/>In the coming weeks, the mechanical glove prototype will be fully manufactured and assembled, and the team hope to integrate the Rockaway game with the glove electronics by then. As one would imagine, the last step of system integration will be a challenge in many areas. The team is looking forward to the process and update this blog as new progress comes along.
          </p>

          <div class="col-xs-12">
            <img class="col-xs-2 col-xs-offset-5" src="images/feather2.png"/>
          </div>
        </div>
      </div>

      <hr/>

      <!-- **************** -->

      <div class="row blog-entry">
        <div class="col-md-10 col-md-offset-1 section-title">
          <h1>A Brief Introduction to HappenVR</h1>
          <p class="subtitle">January 10, 2017 | by: Si Te Feng</p>
          <hr/>
        </div>

        <div class="col-md-10 col-md-offset-1">
          <p class="blog-body">Stroke is a leading cause of adult disability in Canada as well as most countries around the world. There exists a need to improve conventional therapy since only 10% of stroke patients in Canada recover completely [1]. Studies have shown that by increasing the intensity and quantity of exercises, as well as improving patient engagement and motivation, stroke recovery can be improved. Team Happen aims to develop a Virtual Reality Haptic Glove that provides immersive stroke therapy, recovery metrics based on data from the userâs kinematics, and the ability to train independently at home. 

          <br/><br/>The final solution must be functional for at least one hand, provide visual, force and tactile feedbacks while the patient interacts with a virtual environment, and must be safe to use. While considering potential solutions, the team used selection criteria including minimum interaction delay, as well as a high range of motion with minimal biomechanical impedance to ensure an immersive experience for the user. The final solution can be broadly divided into 4 systems which include force feedback, tactile feedback, motion tracking, and software for virtual reality and recovery metrics. Each of these systems is explored in this report, where each team member contributed to their respective section.

          <br/><br/>The force feedback system involves the use of a pull-wire soft exoskeleton that restricts the fingers through soft cables driven by stepper motors. This solution allows the user to experience force feedback and physical restrictions while interacting with virtual objects. In terms of tactile feedback, the final solution selected is the electrotactile system, where regulated current is passed through the skin of the fingertip to directly stimulate the nerve fibers connected to mechanoreceptors. This results in perception of tactile sensations like pressure, vibration, and skin stretch. This solution allows the user to experience the shape and texture of virtual objects, providing an immersive experience aimed at improving stroke therapy. The third system is the motion tracking system, which involves the use of Inertial Measurement Unit (IMU) sensors to track the position and orientation of the hand, as well as the pull-wire system coupled with rotary encoders to track finger joint angles. Lastly, the software system for virtual reality and recovery metrics involves Unity 3D graphics framework, a 3D model creation application called Blender, and the Arduino embedded platform. It provides a critical role in interfacing between sensors and actuators through digital control systems, while providing intelligent recovery tracking and expert metrics for stroke patients.

          <br/><br/>In terms of project budget, the current total is estimated to be 2,100 CAD, where 1081.09 CAD of which are expenses to date (September-December 2016). Meanwhile, 1,000 CAD is set as the budget for the 4B term (January - March 2017).

          <br/><br/>The team is on schedule to completing the final prototype for the Capstone Symposium in March 2017. Since September 2016, the team has completed early prototyping and final design for all 4 major systems, and will proceed to implementing and testing the final solutions for each system. In addition, the team will initiate system integration in early February followed by system testing, fine tuning, and demo preparation in late February.

          <br/><br/>*[1] Ontario Stroke Network, "Stroke Stats and Facts," Cardiac Care Network, 2016. [Online]. Available: http://ontariostrokenetwork.ca/information-about- stroke/stroke-stats-and-facts/. [Accessed 4 December 2016].
          </p>

          <div class="col-xs-12">
              <img class="col-xs-2 col-xs-offset-5" src="images/feather2.png"/>
          </div>
          <br/>
        </div>
      </div>

<!-- End of blog section -->
    </div> 

    <div class="row">
      <div class="col-xs-12">
        <footer>HappenVR Â© 2016-2017 ALL RIGHTS RESERVED</footer>
      </div>
    </div>

    
  </body>
</html>
